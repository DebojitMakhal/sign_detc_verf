{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Siamese Network for Signature Verification\n",
                "\n",
                "This notebook implements a **Siamese Network** to learn a similarity metric between signatures. \n",
                "Goal: Distinguish between **Genuine-Genuine** pairs (same person) and **Genuine-Forged** pairs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import random\n",
                "import glob\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, models, optimizers, callbacks\n",
                "from tensorflow.keras import backend as K\n",
                "\n",
                "# Set Random Seeds\n",
                "random.seed(42)\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)\n",
                "\n",
                "# Check GPU\n",
                "gpus = tf.config.list_physical_devices('GPU')\n",
                "if gpus:\n",
                "    try:\n",
                "        for gpu in gpus:\n",
                "            tf.config.experimental.set_memory_growth(gpu, True)\n",
                "        print(f\"GPU Detected: {gpus}\")\n",
                "    except RuntimeError as e:\n",
                "        print(e)\n",
                "else:\n",
                "    print(\"No GPU detected. Running on CPU.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration\n",
                "IMG_SIZE = (224, 224)\n",
                "BATCH_SIZE = 32\n",
                "SOURCE_DIR = \"signatures\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Preparation\n",
                "We load data directly from the `signatures` source directory and organize it by person ID. This facilitates easy pair generation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data(source_dir):\n",
                "    \"\"\"\n",
                "    Loads genuine and forged signatures, grouping them by Person ID.\n",
                "    Returns: dict { person_id: {'genuine': [paths], 'forged': [paths]} }\n",
                "    \"\"\"\n",
                "    data = {}\n",
                "    if not os.path.exists(source_dir):\n",
                "        print(f\"Error: Source directory '{source_dir}' not found.\")\n",
                "        return data\n",
                "\n",
                "    subdirs = os.listdir(source_dir)\n",
                "    for folder in subdirs:\n",
                "        path = os.path.join(source_dir, folder)\n",
                "        if not os.path.isdir(path): continue\n",
                "        \n",
                "        # Parse Person ID from folder name (e.g., '001', '001_forg')\n",
                "        if '_forg' in folder:\n",
                "            person_id = folder.replace('_forg', '')\n",
                "            cat = 'forged'\n",
                "        else:\n",
                "            person_id = folder\n",
                "            cat = 'genuine'\n",
                "        \n",
                "        if person_id not in data:\n",
                "            data[person_id] = {'genuine': [], 'forged': []}\n",
                "            \n",
                "        # Get all image files\n",
                "        files = glob.glob(os.path.join(path, \"*\"))\n",
                "        files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
                "        data[person_id][cat].extend(files)\n",
                "        \n",
                "    return data\n",
                "\n",
                "data_dict = load_data(SOURCE_DIR)\n",
                "print(f\"Loaded {len(data_dict)} people.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Pair Generation\n",
                "We define a function to generate pairs:\n",
                "- **Positive (Label 1)**: Two Genuine signatures of the same person.\n",
                "- **Negative (Label 0)**: One Genuine and one Forged signature of the same person.\n",
                "\n",
                "We also split the data into **Train** and **Test** sets based on Person IDs (80/20)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_pairs(data_dict, person_ids):\n",
                "    \"\"\"\n",
                "    Generates pairs of paths: (image_A, image_B) and labels.\n",
                "    \"\"\"\n",
                "    pairs_1 = []\n",
                "    pairs_2 = []\n",
                "    labels = []\n",
                "    \n",
                "    for pid in person_ids:\n",
                "        gens = data_dict[pid]['genuine']\n",
                "        forgs = data_dict[pid]['forged']\n",
                "        \n",
                "        if len(gens) < 2: \n",
                "            continue\n",
                "        \n",
                "        # --- Positive Pairs (Genuine + Genuine) ---\n",
                "        # We take adjacent pairs to keep it simple and balanced, or all pairs\n",
                "        # Here we try to create as many pairs as possible without explosion\n",
                "        for i in range(len(gens)):\n",
                "            for j in range(i+1, len(gens)):\n",
                "                pairs_1.append(gens[i])\n",
                "                pairs_2.append(gens[j])\n",
                "                labels.append(1.0) # 0 distance ideally -> Label depends on loss choice. \n",
                "                                   # Standard contrastive: 1 = same, 0 = different? Or 0=same?\n",
                "                                   # Let's use: 0 = Different, 1 = Same\n",
                "                \n",
                "        # --- Negative Pairs (Genuine + Forged) ---\n",
                "        # Pair every genuine with every forged\n",
                "        # If too many forged, we can subsample\n",
                "        for g in gens:\n",
                "            for f in forgs:\n",
                "                pairs_1.append(g)\n",
                "                pairs_2.append(f)\n",
                "                labels.append(0.0) \n",
                "    \n",
                "    return np.array(pairs_1), np.array(pairs_2), np.array(labels).astype('float32')\n",
                "\n",
                "# Split IDs\n",
                "all_ids = list(data_dict.keys())\n",
                "random.shuffle(all_ids)\n",
                "split_idx = int(0.8 * len(all_ids))\n",
                "train_ids = all_ids[:split_idx]\n",
                "test_ids = all_ids[split_idx:]\n",
                "\n",
                "print(f\"Train People: {len(train_ids)}, Test People: {len(test_ids)}\")\n",
                "\n",
                "# Generate Pairs\n",
                "tr_p1, tr_p2, tr_y = make_pairs(data_dict, train_ids)\n",
                "te_p1, te_p2, te_y = make_pairs(data_dict, test_ids)\n",
                "\n",
                "print(f\"Train Pairs: {len(tr_y)} (Positive: {np.sum(tr_y==1)}, Negative: {np.sum(tr_y==0)})\")\n",
                "print(f\"Test Pairs: {len(te_y)} (Positive: {np.sum(te_y==1)}, Negative: {np.sum(te_y==0)})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TF Data Pipeline\n",
                "def preprocess_image(path):\n",
                "    img = tf.io.read_file(path)\n",
                "    img = tf.image.decode_jpeg(img, channels=3)\n",
                "    img = tf.image.resize(img, IMG_SIZE)\n",
                "    img = img / 255.0\n",
                "    return img\n",
                "\n",
                "def preprocess_pair(path1, path2, label):\n",
                "    return (preprocess_image(path1), preprocess_image(path2)), label\n",
                "\n",
                "def create_dataset(p1, p2, y, batch_size=32, shuffle=True):\n",
                "    ds = tf.data.Dataset.from_tensor_slices((p1, p2, y))\n",
                "    if shuffle:\n",
                "        ds = ds.shuffle(buffer_size=1024)\n",
                "    ds = ds.map(preprocess_pair, num_parallel_calls=tf.data.AUTOTUNE)\n",
                "    ds = ds.batch(batch_size)\n",
                "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
                "    return ds\n",
                "\n",
                "train_ds = create_dataset(tr_p1, tr_p2, tr_y, BATCH_SIZE)\n",
                "test_ds = create_dataset(te_p1, te_p2, te_y, BATCH_SIZE, shuffle=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization\n",
                "def visualize_pairs(dataset, num_pairs=5):\n",
                "    (img1_b, img2_b), label_b = next(iter(dataset))\n",
                "    \n",
                "    plt.figure(figsize=(15, 6))\n",
                "    for i in range(num_pairs):\n",
                "        ax = plt.subplot(2, num_pairs, i + 1)\n",
                "        plt.imshow(img1_b[i])\n",
                "        plt.title(\"Signature 1\")\n",
                "        plt.axis(\"off\")\n",
                "        \n",
                "        ax = plt.subplot(2, num_pairs, i + 1 + num_pairs)\n",
                "        plt.imshow(img2_b[i])\n",
                "        lbl_text = \"Genuine\" if label_b[i]==1 else \"Forged Pair\"\n",
                "        plt.title(f\"Sig 2: {lbl_text}\")\n",
                "        plt.axis(\"off\")\n",
                "    plt.show()\n",
                "\n",
                "visualize_pairs(train_ds)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Model Architecture\n",
                "We define the Siamese Network:\n",
                "1.  **Embedding Network**: A CNN that maps images to a 128-dimensional vector.\n",
                "2.  **Distance Layer**: Computes Euclidean distance between two embeddings.\n",
                "3.  **Siamese Model**: Wraps the above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_embedding_network(input_shape):\n",
                "    inputs = layers.Input(shape=input_shape)\n",
                "    \n",
                "    # Standard CNN blocks\n",
                "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
                "    x = layers.MaxPooling2D((2, 2))(x)\n",
                "    x = layers.BatchNormalization()(x)\n",
                "    \n",
                "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
                "    x = layers.MaxPooling2D((2, 2))(x)\n",
                "    x = layers.BatchNormalization()(x)\n",
                "\n",
                "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
                "    x = layers.MaxPooling2D((2, 2))(x)\n",
                "    x = layers.BatchNormalization()(x)\n",
                "    \n",
                "    x = layers.Flatten()(x)\n",
                "    x = layers.Dense(256, activation='relu')(x)\n",
                "    x = layers.Dense(128)(x) # Embedding vector\n",
                "    \n",
                "    return models.Model(inputs, x, name=\"embedding_network\")\n",
                "\n",
                "def euclidean_distance(vectors):\n",
                "    (featA, featB) = vectors\n",
                "    sum_squared = K.sum(K.square(featA - featB), axis=1, keepdims=True)\n",
                "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build Siamese Network\n",
                "input_shape = IMG_SIZE + (3,)\n",
                "\n",
                "img_a = layers.Input(shape=input_shape)\n",
                "img_b = layers.Input(shape=input_shape)\n",
                "\n",
                "embedding_net = build_embedding_network(input_shape)\n",
                "feat_a = embedding_net(img_a)\n",
                "feat_b = embedding_net(img_b)\n",
                "\n",
                "distance = layers.Lambda(euclidean_distance, output_shape=(1,))([feat_a, feat_b])\n",
                "\n",
                "model = models.Model(inputs=[img_a, img_b], outputs=distance)\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training Configuration\n",
                "We use **Contrastive Loss**.\n",
                "- Label 1 (Similar): Minimize distance (Distance -> 0).\n",
                "- Label 0 (Dissimilar): Maximize distance (Distance -> Margin).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def contrastive_loss(y_true, y_pred, margin=1.0):\n",
                "    # y_true: 1 for same, 0 for different\n",
                "    # y_pred: distance\n",
                "    \n",
                "    square_pred = K.square(y_pred)\n",
                "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
                "    \n",
                "    # Loss = (y_true * square_pred) + ((1 - y_true) * margin_square)\n",
                "    # Wait! Standard contrastive often uses 1=same -> dist=0\n",
                "    # Let's check: If y_true=1 (Same), we want dist (y_pred) to be small. -> y_true * square_pred. Correct.\n",
                "    # If y_true=0 (Diff), we want dist to be large (up to margin). -> (1-y) * margin_square. Correct.\n",
                "    \n",
                "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
                "\n",
                "model.compile(loss=contrastive_loss, optimizer='rmsprop')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training\n",
                "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
                "\n",
                "history = model.fit(\n",
                "    train_ds,\n",
                "    validation_data=test_ds,\n",
                "    epochs=10,\n",
                "    callbacks=[early_stopping]\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluation\n",
                "We check the model's ability to distinguish pairs. \n",
                "We compute accuracy by applying a fixed threshold (e.g., 0.5) to the distance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_accuracy(y_true, y_pred, threshold=0.5):\n",
                "    # If distance < threshold -> Predicted Same (1)\n",
                "    # Else -> Predicted Different (0)\n",
                "    pred_labels = (y_pred < threshold).astype(int)\n",
                "    return np.mean(pred_labels == y_true)\n",
                "\n",
                "# Get predictions for Test set\n",
                "print(\"Predicting on Test Set...\")\n",
                "predictions = model.predict(test_ds)\n",
                "\n",
                "accuracy = compute_accuracy(te_y, predictions.ravel())\n",
                "print(f\"Test Accuracy (Threshold=0.5): {accuracy * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize Training History\n",
                "plt.plot(history.history['loss'], label='Train Loss')\n",
                "plt.plot(history.history['val_loss'], label='Val Loss')\n",
                "plt.legend()\n",
                "plt.title('Training Loss')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizing Test Results\n",
                "def show_results(dataset, predictions, num_pairs=5):\n",
                "    # We pick first batch visually, but need corresponding predictions\n",
                "    # Note: dataset is batched. predictions are flat array for whole dataset.\n",
                "    # We need to map them manually or iterate carefully.\n",
                "    \n",
                "    (img1_b, img2_b), label_b = next(iter(dataset))\n",
                "    batch_preds = predictions[:len(label_b)] # Approximation for first batch\n",
                "    \n",
                "    plt.figure(figsize=(15, 8))\n",
                "    for i in range(num_pairs):\n",
                "        ax = plt.subplot(2, num_pairs, i + 1)\n",
                "        plt.imshow(img1_b[i])\n",
                "        plt.axis(\"off\")\n",
                "        \n",
                "        ax = plt.subplot(2, num_pairs, i + 1 + num_pairs)\n",
                "        plt.imshow(img2_b[i])\n",
                "        \n",
                "        dist = batch_preds[i]\n",
                "        true_lbl = \"Same\" if label_b[i]==1 else \"Diff\"\n",
                "        pred_lbl = \"Same\" if dist < 0.5 else \"Diff\"\n",
                "        \n",
                "        color = \"green\" if true_lbl == pred_lbl else \"red\"\n",
                "        \n",
                "        plt.title(f\"D:{dist:.2f} | T:{true_lbl} P:{pred_lbl}\", color=color)\n",
                "        plt.axis(\"off\")\n",
                "    plt.show()\n",
                "\n",
                "show_results(test_ds, predictions)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}